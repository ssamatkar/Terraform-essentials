Terraform Labs Steps
====================

Login to AWS Console


###################################
Lab 1: Creating an EC2 Instance in AWS and Installing Terraform
###################################

Task 1: Installing Terraform on Ubuntu 20.04 operating system
=============================================================
Launch a t2.micro instance with OS version Ubuntu 20.04 (North Virginia / us-east-1)
In sec group, include ports 22 and 80. Use tag 'Name:Terraform'

login with username as ubuntu

After EC2 is ready:

sudo hostnamectl set-hostname terraform
# Hostname will appear if you exit and login again. Or you can type 'bash' and open another shell

sudo apt update
sudo apt install wget unzip -y

#old version
wget https://releases.hashicorp.com/terraform/1.2.8/terraform_1.2.8_linux_amd64.zip
unzip terraform_1.2.8_linux_amd64.zip

#new version
wget https://releases.hashicorp.com/terraform/1.4.0/terraform_1.4.0_linux_amd64.zip
unzip terraform_1.4.0_linux_amd64.zip

ls
sudo mv terraform /usr/local/bin
ls
terraform
terraform -v


Task 2: Install and login to Ubuntu server from AWS EC2 Instance 
======================================================

sudo apt-get install python3-pip -y
sudo pip3 install awscli

aws configure
Add AKID
Add SAK

aws s3 ls

Task-2.1:# Now we are ready to perform the labs
#########################################
create directory as Lab1

create local file
---------------------
vi local.tf

resource	"local_file"  "myfile"  {

	filename = "/home/ubuntu/test.txt"
	content  = "wel come to terraform"
}

terraform init
terraform plan
terraform apply

#########################################

###################################
Task 3: Launching your first AWS EC2 instance using Terraform 
###################################

mkdir terraform-labs && cd terraform-labs/

vi example.tf

# Add the given lines, by pressing "INSERT" 

provider "aws" {
  profile = "default" # This line is not mandatory.
  region  = "us-east-2"
}

resource "aws_instance" "example" {
  ami           = "ami-00eeedc4036573771"
  instance_type = "t2.micro"
  tags = {
    Name = "Yourname-TF-1"
  }
}


# save the file using "ESCAPE + :wq!"

terraform init
terraform fmt
terraform validate
terraform plan
terraform apply

ls
cat terraform.tfstate

# Now, change the AMI id
vi example.tf

# Add the given lines, by pressing "INSERT" 

provider "aws" {
  profile = "default"
  region  = "us-east-2"
}

resource "aws_instance" "example" {
  ami           = "ami-0521a1ab6cb98215d"
  instance_type = "t2.micro"
  tags = {
    Name = "Yourname-TF-1"
  }
}


# save the file using "ESCAPE + :wq!"

terraform plan
terraform apply
cat terraform.tfstate

# Use the "terraform destroy" command for cleaning the infrastructure used in this lab
terraform destroy




###################################
Lab 2: AWS EC2 instance creation using Terraform Variables
###################################

Task 1: Create EC2 instance using variables 
===========================================
cd /home/ubuntu/terraform-labs/
mkdir variables-lab && cd variables-lab/

vi provider.tf

# Add the given lines, by pressing "INSERT" 

provider "aws"{
  access_key=var.AWS_ACCESS_KEY
  secret_key=var.AWS_SECRET_KEY
  region=var.AWS_REGION
}

# save the file using "ESCAPE + :wq!"

vi vars.tf

# Add the given lines, by pressing "INSERT" 

variable "AWS_ACCESS_KEY"{}
variable "AWS_SECRET_KEY"{}
variable "AWS_REGION"{
  default = "us-east-2"
}

# save the file using "ESCAPE + :wq!"

vi terraform.tfvars

# Add the given lines, by pressing "INSERT" 

AWS_ACCESS_KEY="< Insert your AWS Access Key >"
AWS_SECRET_KEY="< Insert your AWS Secret Key >"


# save the file using "ESCAPE + :wq!"

vi instance.tf

# Add the given lines, by pressing "INSERT" 

resource "aws_instance" "terraform_example"{
  ami = "ami-0d5d9d301c853a04a"
  instance_type="t2.micro"
  tags = {
    Name = "Lab2-yourname"
  }
}

# save the file using "ESCAPE + :wq!"

terraform init
terraform plan
terraform apply


# Use the "terraform destroy" command for cleaning the infrastructure used in this lab
terraform destroy -auto-approve

# Additional Note
# If the name of the tfvars files is anything other than terraform.tfvars then you can 
# use the below command.
terraform apply -var-file=<var file name>



Task 2: Implementing map variables that dynamically fetch AMI based on the Linux distro selected
================================================================================================


vi instance.tf

# Delete the existing lines and Add the given lines, by pressing "INSERT" 

resource "aws_instance" "terraform_example"{
  ami = var.AMIS[var.Linux_distro]
  instance_type="t2.micro"
  tags = {
    Name = "yourname-lab8B-task2"
  }
}

# save the file using "ESCAPE + :wq!"

vi vars.tf

# Delete the existing lines and Add the given lines, by pressing "INSERT" 

variable "AWS_ACCESS_KEY"{}
variable "AWS_SECRET_KEY"{}
variable "AWS_REGION"{
  default = "us-east-2"
  }

variable "Linux_distro"{
  #description="Please Enter the Linux distro (redhat , ubuntu, amazon )"
  default = "amazon"
  }

variable "AMIS"{
  type=map(string)
  default={
   redhat="ami-0ba62214afa52bec7"
   ubuntu="ami-0fb653ca2d3203ac1"
   amazon="ami-0231217be14a6f3ba"
  }
}

# save the file using "ESCAPE + :wq!"


terraform fmt
terraform validate
terraform plan -var 'Linux_distro=redhat' -out myplan
terraform apply myplan


# Use the "terraform destroy" command for cleaning the infrastructure used in this lab
terraform destroy



###################################
Lab 3 : Using Output Feature 
###################################


Task 1: Using output feature of Terraform to get the IP Address of EC2 Instance
===============================================================================

cd /home/ubuntu/
wget http://s3.ap-south-1.amazonaws.com/files.cloudthat.training/devops/terraform-essentials/output-variable-lab-v0.13.5.tar.gz
tar -xvf output-variable-lab-v0.13.5.tar.gz
cd output-variable-lab/
ls

cat instance.tf
cat output.tf
cat vars.tf

terraform init
terraform fmt
terraform validate
terraform plan
terraform apply

ls 
cat private_ips.txt 

terraform output Public_ip
terraform output Private_ip

# Use the "terraform destroy" command for cleaning the infrastructure used in this lab, remove the 
  directory using rm -rf

terraform destroy

cd ..
rm -rf output-variable-lab

#####################################################
Lab 4: Understanding local values, functions and data sources
#####################################################

Task 1: Local Values 
======================================================
mkdir lab4 && cd lab4
mkdir task1 && cd task1

vi local.tf

# Add the given lines, by pressing "INSERT" 

provider "aws" {
  region     = "us-west-1"
}

locals {
  custom_tags = {
    Team = "DevOps"
    comapny = "CloudThat"
  }
}
resource "aws_instance" "instance1" {
   ami = "ami-060d3509162bcc386"
   instance_type = "t2.micro"
   tags = local.custom_tags
}

resource "aws_instance" "instance2" {
   ami = "ami-0d50e5e845c552faf"
   instance_type = "t2.small"
   tags = local.custom_tags
}

resource "aws_ebs_volume" "db_ebs" {
  availability_zone = "us-west-1a"
  size              = 8
  tags = local.custom_tags
}

# save the file using "ESCAPE + :wq!"

terraform init
terraform plan
terraform apply

Task 2: Functions
=========================================================

cd ..
mkdir task2 && cd task2
vi functions.tf

provider "aws" {
  region     = var.region
}

variable "region" {
  default = "ap-south-1"
}

variable "tags" {
  type = list
  default = ["ec2-1","ec2-2"]
}

variable "ami" {
  type = map
  default = {
    "us-east-1" = "ami-006dcf34c09e50022"
    "us-west-1" = "ami-060d3509162bcc386"
    "ap-south-1" = "ami-09ba48996007c8b50"
  }
}

resource "aws_instance" "application-servers" {
   ami = lookup(var.ami,var.region)
   instance_type = "t2.micro"
   count = 2

   tags = {
     Name = element(var.tags,count.index)
   }
}
# save the file using "ESCAPE + :wq!"

terraform init
terraform plan
terraform apply

Task 3: Data sources
==========================================================

cd ..
mkdir task3 && cd task3
vi data.tf

# Add the given lines, by pressing "INSERT" 

provider "aws" {
  region     = "us-east-2"
}

data "aws_ami" "ami" {
  most_recent = true
  owners = ["amazon"]


  filter {
    name   = "name"
    values = ["amzn2-ami-hvm*"]
  }
}

resource "aws_instance" "ec2instance" {
    ami = data.aws_ami.ami.id
   instance_type = "t2.micro"
}

# save the file using "ESCAPE + :wq!"

terraform init
terraform plan
terraform apply


Lab 5 : Remote State using Amazon Simple Storage Service 
###################################

Task 1: Create a S3 Bucket on AWS Console 
=========================================
Create a new S3 bucket by name: yourname-terraform. Remove block public access.
select -I acknowledge that the current settings might result in this bucket and the objects within becoming public.
Select ACLs enabled
select-I acknowledge that ACLs will be restored.
enable versioning. 

aws s3 ls 


Task 2: Configure Remote State
==============================
cd /home/ubuntu/terraform-labs/
wget http://s3.ap-south-1.amazonaws.com/files.cloudthat.training/devops/terraform-essentials/remote_state_lab.tar.gz
tar -zxvf remote_state_lab.tar.gz
cd remote-state-lab
ls

cat instance.tf
cat vars.tf
cat provider.tf

vi backend.tf

# Add the given lines, by pressing "INSERT" 

terraform {
  backend "s3" {
    bucket = "<Replace your s3 bucket name>"
    key    = "terraform/remotestate"
  }
}

# save the file using "ESCAPE + :wq!"

cat backend.tf

terraform init
terraform fmt
terraform validate
terraform plan
terraform apply

##Go to s3 bucket and open the s3 bucket open terraform/remotestate
Click on permision and click on under acl contrl list edit 
select read under objects. 
select-I understand the effects of these changes on this object.
click on save changes
copy object url and paste in the web browser.
you should able to access the state file.



# This command shows the attributes of a single resource in the Terraform state.
terraform state show aws_instance.terraform-remoteState

# Use the "terraform destroy" command for cleaning the infrastructure used in this lab, 
# remove the directory using rm -rf

terraform destroy

cd ..
rm -rf remote-state-lab


#######################################
Lab 6 : Launching VPC and EC2 Instance 
#######################################

Task 1: Launching VPC and creating subnets
==========================================

cd /home/ubuntu/
wget https://s3.ap-south-1.amazonaws.com/files.cloudthat.training/devops/terraform-essentials/vpc_lab.zip
unzip vpc_lab.zip


cd vpc_lab
ls

cat vpc.tf
cat nat.tf
cat vars.tf

terraform init
terraform plan
terraform apply -auto-approve
 

Task 2: Launching an EC2 Instance 
=================================
vi instance.tf 

# Add the given lines, by pressing "INSERT" 

resource "aws_instance" "example" {
  ami           = var.AMIS[var.AWS_REGION]
  instance_type = "t2.micro"
  # the VPC subnet
  subnet_id = aws_subnet.main-public-1.id
  # the security group
  vpc_security_group_ids = [aws_security_group.allow-ssh.id]
  # the public SSH key
  key_name = aws_key_pair.mykeypair.key_name
  tags = {
    Name = "Yourname-Lab11-ec2"
  }
}


# save the file using "ESCAPE + :wq!"

vi securitygroup.tf

# Add the given lines, by pressing "INSERT" 

resource "aws_security_group" "allow-ssh" {
  vpc_id      = aws_vpc.main.id
  name        = "yourname-allow-ssh"
  description = "security group that allows ssh and all egress traffic"
  egress {
    from_port   = 0
    to_port     = 0
    protocol    = "-1"
    cidr_blocks = ["0.0.0.0/0"]
  }
  ingress {
    from_port   = 22
    to_port     = 22
    protocol    = "tcp"
    cidr_blocks = ["0.0.0.0/0"]
  }
  tags = {
    Name = "yourname-allow-ssh"
  }
}


# save the file using "ESCAPE + :wq!"

ssh-keygen -f mykey
ls
vi key.tf

# Add the given lines, by pressing "INSERT" 

resource "aws_key_pair" "mykeypair" {
  key_name   = "yourname-keypair"
  public_key = file(var.PATH_TO_PUBLIC_KEY)
}

# save the file using "ESCAPE + :wq!"

vi vars.tf

# Add the given lines, by pressing "INSERT" 
# First 3 lines are already present. you can add the remaining lines.

variable "AWS_REGION" {
  default = "us-east-2"
}

variable "PATH_TO_PUBLIC_KEY" {
  default = "mykey.pub"
}

variable "AMIS" {
  type = map(string)
  default = {
    us-east-2 = "ami-059d836af932792c3"
    us-west-2 = "ami-0a7d051a1c4b54f65"
    eu-west-1 = "ami-04c58523038d79132"
  }
}


# save the file using "ESCAPE + :wq!"

terraform fmt
terraform validate
terraform plan
terraform apply -auto-approve

# see details of the specific resource
terraform state show aws_instance.example | grep public_ip

ssh -i mykey -l ubuntu <Your Public IP>

exit


Task 3: Connecting an EBS with EC2 Instance 
===========================================

vi instance.tf 

# Add the given lines, by pressing "INSERT" 
# First block will be already present in the file

resource "aws_instance" "example" {
  ami = var.AMIS[var.AWS_REGION]
  instance_type = "t2.micro"
  # the VPC subnet
  subnet_id = aws_subnet.main-public-1.id
  # the security group
  vpc_security_group_ids = [aws_security_group.allow-ssh.id]
  # the public SSH key
  key_name = aws_key_pair.mykeypair.key_name
  tags = {
    Name = "yourname-Lab11-EC2"
  }
}

resource "aws_ebs_volume" "ebs-volume-1" {
 availability_zone = "us-east-2a"
 size = 20
 type = "gp2"
 tags = {
   Name = "Yourname extra volume"
 }
}

resource "aws_volume_attachment" "ebs-volume-1-attachment" {
  device_name = "/dev/xvdh"
  volume_id = aws_ebs_volume.ebs-volume-1.id
  instance_id = aws_instance.example.id
} 

# save the file using "ESCAPE + :wq!"

terraform apply

Login to ec2 dashboard. select the ec2. go to storage and see that the new volume is attached
ssh -i mykey ubuntu@<PUBLIC IP>


# Use the "terraform destroy" command for cleaning the infrastructure used in this lab, remove the 
  directory using rm -rf

terraform destroy -auto-approve

cd ..
rm -rf lab_10_vpc



###################################
Lab-7: Launching auto scaling services
###################################

Task 1: Create ASG
-------------------
cd /home/ubuntu/

wget https://s3.ap-south-1.amazonaws.com/files.cloudthat.training/devops/terraform-essentials/autoscaling_lab.zip
unzip autoscaling_lab.zip	
cd autoscaling_lab/

ls
vi autoscaling.tf
Update the names/tags to include your name

vi autoscalingpolicy.tf
Update the names/tags to include your name

ssh-keygen -f mykey
ls

terraform init
terraform plan
terraform apply 


Task 2: Increase CPU utilization in your new ec2 instance.
----------------------------------------------------------
ssh -i mykey -l ubuntu <Public IP> 

sudo apt-get update
sudo apt-get install stress

# 2 workers spawning sqrt() function. will do for 300 seconds

stress --cpu 3 -v --timeout 300

Follow digify document to observe the metrics for ec2 and the alrams in cloudwatch


# Now go back to AWS console > Services > EC2 > Instances and select your instance. Go to its description 
  and click on Monitoring. You see High CPU utilization  
# Go to AWS console > Services > CloudWatch > Alarms and view alarm  
# Go to AWS console > Services > EC2 > Instances. You can see that one more instance is created with same 
  name.  


terraform destroy


####################
Lab-8: IAM
#####################
vi iam.tf
# group definition
resource "aws_iam_group" "devgroup" {
  name = "testgroup"
}


# user
resource "aws_iam_user" "user1" {
  name = "testuser1"
}

resource "aws_iam_user" "user2" {
  name = "testuser2"
}

resource "aws_iam_group_membership" "group-users" {
  name = "group-users"
  users = [
    aws_iam_user.user1.name,
    aws_iam_user.user2.name,
  ]
  group = aws_iam_group.devgroup.name
}


-------------------
vi provider.tf
provider "aws" {
  region = var.AWS_REGION
}

--------------
vi vars.tf
variable "AWS_REGION" {
  default = "us-east-2"
}


###################################
Lab 9 : Creating AWS resources using terraform modules
###################################

cd /home/ubuntu/
sudo apt install tree -y

wget http://s3.ap-south-1.amazonaws.com/files.cloudthat.training/devops/terraform-essentials/terraform-modules.tar.gz
tar -xvf terraform-modules.tar.gz

cd terraform-modules
tree

# cat all files to see the module structure
vi main.tf
# Add the below code after block module "my_security_group"
output "secgrpid" {
  description = "Newly created sec grp"
  value       = module.my_security_group.sgid
}

cat provider.tf
# no change needed

vi variables.tf 

# Modify the VPC / Subnet ID / key_name

-Change vpc_id to any VPC in ca-central-1 (ex:vpc-10102478)
-Change subnet id (use available subnets from AZ a or b. ex: subnet-5189d339)
-Change key_name to yourname-Lab12-keypair (ex: martuj-Lab12-keypair)


variable "region" {
    default = "ca-central-1"
}

# enter VPC id
variable "sg_vpcid" {
    default = "Your VPC ID"
}

variable "from_port" {
    default = 22
}

variable "to_port" {
    default = 22
}

# security grp name to be created
variable  "sg_name" {
    default = "terraform-sgp"
}

variable "ami_id" {
    default = "ami-0e28822503eeedddc"
}

variable "ins_type" {
    default = "t2.micro"
}

# enter a subnet id from Zone A or B
variable sub_id {
    default = "Your Subnet ID"
}

# add your name in key_name
variable key_name {
    default = "yourname-key-pair-lab9"
}

variable from_port2 {
    default = 80
}

variable to_port2 {
    default = 80
}

variable public_key {
    default = "mykey.pub"
}

# Save

# Create a key pair. The public key of the same will be saved into the EC2 being launched.
ssh-keygen -f mykey

terraform init
terraform fmt
terraform validate
terraform plan
terraform apply -auto-approve

Self Exercise Task:
# Add lines of code to print out the id of the new ec2 created (module.my_ec2.ec2_id)
# You can refer to how security grp id is outputted.

terraform destroy


####################################################################
Lab 10: Terraform Cloud
###################################################################

Task 1: create a terraform cloud account
====================================================================

Task 2: Create a new repo in Github
====================================================================
Sign in in Github

Click on New
In the repository name: Enter "Terraform-Cloud"
Click on Private
Click on Create Repository
Click on creating a new file
Name your file vars.tf
Add the following code
variable "AWS_ACCESS_KEY"{} 
variable "AWS_SECRET_KEY"{} 
Click on commit new file.
Add another file by clicking on add file dropdown and select create new file. 
Name the file as instance.tf, Insert the below contents and commit the file. 

provider "aws" { 
region = "sa-east-1" 
access_key=var.AWS_ACCESS_KEY 
secret_key=var.AWS_SECRET_KEY 
} 

resource "aws_instance" "web" { 
ami           = "ami-02dc8ad50da58fffd" 
instance_type = "t2.micro" 
tags = { 
Name = "HelloWorld" 
} 
}  

Task 3: Create a new workspace
=============================================================================
Click on create a new workspace
In tab 1, Select VCS (Version Control System) 
In tab 2, select Github
Once you click Github.com, a new window will popup. Sign into your GitHub account from there. Perform the verification and install Terraform on Git. 
Now, we have the GitHub account connected with Terraform cloud. In tab 3 choose the repository where Terraform configuration are present, in this case its â€œTerraform-Cloudâ€.
In tab 4, Provide the name for the workspace of  your own choice and click theâ€¯Create Workspaceâ€¯button. Once the workspace is created, you will see a success message in a popup. 

Task 4: Plan and Apply the changes 
=============================================================================
Now on the terraform cloud graphics, clickâ€¯Configure variables. In this demo, we will pass the credentials of AWS (Access key and secret key) to authenticate with users. 
Click on add variable and provide following details. Make sure you enable sensitive check box. 

AWS_ACCESS_KEY = Your aws access key 

AWS_SECRET_ACCESS_KEY = Your aws secret key 

Click onâ€¯Actionsâ€¯and Start new run and choose the option plan and apply
Once Plan is successful, scroll down a bit, and it will wait for the confirmation/approval to apply the changes. Clickâ€¯Confirm & Apply 
Provide a message in the textbox and click on Confirm Plan 
You will see that terraform apply is happening. 
Verify that the resource has been created in your AWS Console 

Task 5: Terminate the resources 
====================================================================================
On the settings tab, click on Destruction and Deletion 
Now, click onâ€¯Create Destroyâ€¯Plan. 
Provide the Workspace name and click on Queue Destroy plan 
Now you will notice that queue is scheduled. The deletion queue has two stages. Plan and apply (to delete the infra) 
Approve to start the delete operation by clicking Confirm & Apply
Once completed, check the run tab to check the status. 
Check the AWS console to verify that the resources are no longer active. 




